{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e641a52",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fralfaro/DS-Cheat-Sheets/blob/main/docs/examples/polars/st_polars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    " \n",
    "# Polars Cheat Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7570e16a",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #000; background-color: #fff; color: #000; padding: 10px; display: flex; align-items: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/images/info_icon.png\" width=\"100\" style=\"margin-right: 10px;\">\n",
    "    <div>\n",
    "        <strong>Note</strong><br>\n",
    "        If you want to run this example on <a href=\"https://colab.research.google.com/\" target=\"_blank\">Google Colab</a>, follow these detailed steps below:\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "1. Install the necessary libraries:\n",
    "\n",
    "    ```python\n",
    "    !pip install streamlit\n",
    "    ```\n",
    "\n",
    "2. Create your app by executing the following cell:\n",
    "\n",
    "    ```python\n",
    "    %%writefile app.py\n",
    "    import streamlit as st\n",
    "    import pandas as pd\n",
    "    # ... (rest of your code)\n",
    "    ```\n",
    "\n",
    "3. Start your app by running this cell:\n",
    "\n",
    "    ```python\n",
    "    !streamlit run app.py & npx localtunnel --port 8501\n",
    "    ```\n",
    "\n",
    "    ![Example Image](https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/images/img_01.png)\n",
    "\n",
    "    * After completing the above steps, click  \"**your url is: ...**\"  (for example, *https://major-weeks-clap.loca.lt*).  \n",
    "    * In the new  window, enter the numbers in the \"**External URL: ...**\" section (for example, **35.230.186.60**). \n",
    "    * Finally, click **Click to Submit**\n",
    "\n",
    "    ![Example Image](https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/images/img_02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2323507",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75247dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "# Initial page config\n",
    "st.set_page_config(\n",
    "    page_title='Polars Cheat Sheet',\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\",\n",
    ")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to set up the Streamlit app layout.\n",
    "    \"\"\"\n",
    "    cs_sidebar()\n",
    "    cs_body()\n",
    "    return None\n",
    "\n",
    "# Define img_to_bytes() function\n",
    "def img_to_bytes(img_url):\n",
    "    response = requests.get(img_url)\n",
    "    img_bytes = response.content\n",
    "    encoded = base64.b64encode(img_bytes).decode()\n",
    "    return encoded\n",
    "\n",
    "\n",
    "# Define the cs_sidebar() function\n",
    "def cs_sidebar():\n",
    "    \"\"\"\n",
    "    Populate the sidebar with various content sections related to Polars.\n",
    "    \"\"\"\n",
    "    st.sidebar.markdown(\n",
    "        '''[<img src='data:image/svg;base64,{}' class='img-fluid' width=200 >](https://streamlit.io/)'''.format(\n",
    "            img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/polars/polars.png\")), unsafe_allow_html=True)\n",
    "\n",
    "    st.sidebar.header('Polars Cheat Sheet')\n",
    "    st.sidebar.markdown('''\n",
    "<small>[Polars](https://pola-rs.github.io/polars-book/) is a highly performant DataFrame library for manipulating structured data. The core is written in Rust, but the library is also available in Python. </small>\n",
    "    ''', unsafe_allow_html=True)\n",
    "\n",
    "    # Polars installation and import\n",
    "    st.sidebar.markdown('__Install and import Polars__')\n",
    "    st.sidebar.code('$ pip install polars')\n",
    "    st.sidebar.code('''\n",
    "# Import Polars convention\n",
    ">>> import polars as pl\n",
    "''')\n",
    "\n",
    "    # Creating/reading DataFrames\n",
    "    st.sidebar.subheader('Creating/reading DataFrames')\n",
    "    st.sidebar.markdown('__Create DataFrame__')\n",
    "    st.sidebar.code('''\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame(\n",
    "                {\n",
    "                    \"nrs\": [1, 2, 3, None, 5],\n",
    "                    \"names\": [\"foo\", \"ham\", \"spam\", \"egg\", None],\n",
    "                    \"random\": [0.3, 0.7, 0.1, 0.9, 0.6],\n",
    "                    \"groups\": [\"A\", \"A\", \"B\", \"C\", \"B\"],\n",
    "                }\n",
    "            )\n",
    "            ''')\n",
    "    st.sidebar.markdown('__Read CSV__')\n",
    "    st.sidebar.code('''\n",
    "    # Read CSV\n",
    "    df = pl.read_csv(\n",
    "        \"https://j.mp/iriscsv\",\n",
    "         has_header=True\n",
    "    )\n",
    "            ''')\n",
    "    st.sidebar.markdown('__Read parquet__')\n",
    "    st.sidebar.code('''\n",
    "    # Read a Parquet file with selected columns\n",
    "    df = pd.read_parquet(\n",
    "        \"path.parquet\", \n",
    "        columns=[\"select\", \"columns\"]\n",
    "    )\n",
    "            ''')\n",
    "\n",
    "    # Expressions\n",
    "    st.sidebar.subheader('Expressions')\n",
    "    st.sidebar.markdown('''\n",
    "    <small>Polars expressions can be performed in sequence. This improves readability of code. </small>\n",
    "        ''', unsafe_allow_html=True)\n",
    "    st.sidebar.code('''\n",
    "            # Filter rows where 'nrs' column is less than 4,\n",
    "            # then group by 'groups' column and calculate the sum\n",
    "            df.filter(pl.col(\"nrs\") < 4).groupby(\"groups\").agg(pl.all().sum())\n",
    "            ''')\n",
    "\n",
    "\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# Define the cs_body() function\n",
    "def cs_body():\n",
    "    \"\"\"\n",
    "    Create content sections for the main body of the Streamlit cheat sheet with Polars examples.\n",
    "    \"\"\"\n",
    "    col1, col2, col3 = st.columns(3)  # Create columns for layout\n",
    "\n",
    "    #######################################\n",
    "    # COLUMN 1\n",
    "    #######################################\n",
    "\n",
    "    # Filter\n",
    "    col1.subheader(\"Filter\")\n",
    "    col1.code('''\n",
    "            # Extract rows where 'random' column is greater than 0.5\n",
    "            df.filter(pl.col(\"random\") > 0.5)\n",
    "\n",
    "            # Extract rows where 'groups' is \"B\" and 'random' is greater than 0.5\n",
    "            df.filter((pl.col(\"groups\") == \"B\") & (pl.col(\"random\") > 0.5))\n",
    "            ''')\n",
    "\n",
    "    # Sample\n",
    "    col1.subheader(\"Sample\")\n",
    "    col1.code('''\n",
    "            # Randomly select fraction of rows\n",
    "            df.sample(frac=0.5)\n",
    "\n",
    "            # Randomly select n rows\n",
    "            df.sample(n=2)\n",
    "\n",
    "            # Select first n rows\n",
    "            df.head(n=2)\n",
    "\n",
    "            # Select last n rows\n",
    "            df.tail(n=2)\n",
    "            ''')\n",
    "\n",
    "    # Expressions Example\n",
    "    col1.subheader(\"Expressions Example\")\n",
    "    col1.code('''\n",
    "            # Filter rows where 'nrs' column is less than 4,\n",
    "            # then group by 'groups' column and calculate the sum\n",
    "            df.filter(pl.col(\"nrs\") < 4).groupby(\"groups\").agg(pl.all().sum())\n",
    "            ''')\n",
    "\n",
    "    # Subsets - rows and columns\n",
    "    col1.subheader(\"Subsets - rows and columns\")\n",
    "    col1.code('''\n",
    "    # Select rows 2-4\n",
    "    df[2:4, :]\n",
    "    ''')\n",
    "    col1.code('''\n",
    "    # Select columns in positions 1 and 3 (first column is 0)\n",
    "    df[:, [1, 3]]\n",
    "    ''')\n",
    "    col1.code('''\n",
    "    # Select rows meeting logical condition and specific columns\n",
    "    df[df[\"random\"] > 0.5, [\"names\", \"groups\"]]\n",
    "    ''')\n",
    "\n",
    "\n",
    "\n",
    "    #######################################\n",
    "    # COLUMN 2\n",
    "    #######################################\n",
    "\n",
    "    # Reshaping Data – Change layout, sorting, renaming\n",
    "    col1.subheader(\"Reshaping Data – Change layout, sorting, renaming\")\n",
    "    col1.code('''\n",
    "            # Append rows of DataFrames\n",
    "            pl.concat([df, df2])\n",
    "            ''')\n",
    "    col1.code('''\n",
    "            # Append columns of DataFrames\n",
    "            pl.concat([df, df3], how=\"horizontal\")\n",
    "            ''')\n",
    "    col1.code('''\n",
    "            # Gather columns into rows\n",
    "            df.melt(id_vars=\"nrs\", value_vars=[\"names\", \"groups\"])\n",
    "            ''')\n",
    "    col1.code('''\n",
    "            # Spread rows into columns\n",
    "            df.pivot(values=\"nrs\", index=\"groups\", columns=\"names\")\n",
    "            ''')\n",
    "    col1.code('''\n",
    "            # Order rows by values of a column (low to high)\n",
    "            df.sort(\"random\")\n",
    "            ''')\n",
    "    col1.code('''\n",
    "            # Order rows by values of a column (high to low)\n",
    "            df.sort(\"random\", reverse=True)\n",
    "            ''')\n",
    "    col1.code('''\n",
    "            # Rename the columns of a DataFrame\n",
    "            df.rename({\"nrs\": \"idx\"})\n",
    "            ''')\n",
    "    col1.code('''\n",
    "            # Drop columns from DataFrame\n",
    "            df.drop([\"names\", \"random\"])\n",
    "            ''')\n",
    "\n",
    "    #######################################\n",
    "    # COLUMN 3\n",
    "    #######################################\n",
    "\n",
    "    # Summarize Data\n",
    "    col2.subheader(\"Summarize Data\")\n",
    "\n",
    "    col2.code('''\n",
    "            # Count number of rows with each unique value of variable\n",
    "            df[\"groups\"].value_counts()\n",
    "            ''')\n",
    "\n",
    "    col2.code('''\n",
    "            # rows in DataFrame (or df.height)\n",
    "            len(df) \n",
    "            ''')\n",
    "\n",
    "    col2.code('''\n",
    "            # Tuple of # of rows, # of columns in DataFrame\n",
    "            df.shape\n",
    "            ''')\n",
    "\n",
    "    col2.code('''\n",
    "            # of distinct values in a column\n",
    "            df[\"groups\"].n_unique()\n",
    "            ''')\n",
    "\n",
    "    col2.code('''\n",
    "            # Basic descriptive and statistics for each column\n",
    "            df.describe()\n",
    "            ''')\n",
    "\n",
    "    col2.code('''\n",
    "            df.select(\n",
    "                [\n",
    "                    # Sum values\n",
    "                    pl.sum(\"random\").alias(\"sum\"),\n",
    "                    # Minimum value\n",
    "                    pl.min(\"random\").alias(\"min\"),\n",
    "                    # Maximum value\n",
    "                    pl.max(\"random\").alias(\"max\"),\n",
    "                    # or\n",
    "                    pl.col(\"random\").max().alias(\"other_max\"),\n",
    "                    # Standard deviation\n",
    "                    pl.std(\"random\").alias(\"std_dev\"),\n",
    "                    # Variance\n",
    "                    pl.var(\"random\").alias(\"variance\"),\n",
    "                    # Median\n",
    "                    pl.median(\"random\").alias(\"median\"),\n",
    "                    # Mean\n",
    "                    pl.mean(\"random\").alias(\"mean\"),\n",
    "                    # Quantile\n",
    "                    pl.quantile(\"random\", 0.75).alias(\"quantile_0.75\"),\n",
    "                    # or\n",
    "                    pl.col(\"random\").quantile(0.75).alias(\"other_quantile_0.75\"),\n",
    "                    # First value\n",
    "                    pl.first(\"random\").alias(\"first\"),\n",
    "                ]\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "    # Group Data\n",
    "    col2.subheader(\"Group Data\")\n",
    "\n",
    "    col2.code('''\n",
    "            # Group by values in column named 'col', returning a GroupBy object\n",
    "            df.groupby(\"groups\")\n",
    "            ''')\n",
    "\n",
    "    col2.code('''\n",
    "            # All of the aggregation functions from above can be applied to a group as well\n",
    "            df.groupby(by=\"groups\").agg(\n",
    "                [\n",
    "                    # Sum values\n",
    "                    pl.sum(\"random\").alias(\"sum\"),\n",
    "                    # Minimum value\n",
    "                    pl.min(\"random\").alias(\"min\"),\n",
    "                    # Maximum value\n",
    "                    pl.max(\"random\").alias(\"max\"),\n",
    "                    # Standard deviation\n",
    "                    pl.std(\"random\").alias(\"std_dev\"),\n",
    "                    # Variance\n",
    "                    pl.var(\"random\").alias(\"variance\"),\n",
    "                    # Median\n",
    "                    pl.median(\"random\").alias(\"median\"),\n",
    "                    # Mean\n",
    "                    pl.mean(\"random\").alias(\"mean\"),\n",
    "                    # Quantile\n",
    "                    pl.quantile(\"random\", 0.75).alias(\"quantile_0.75\"),\n",
    "                    # First value\n",
    "                    pl.first(\"random\").alias(\"first\"),\n",
    "                ]\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "    col2.code('''\n",
    "            # Additional GroupBy functions\n",
    "            df.groupby(by=\"groups\").agg(\n",
    "                [\n",
    "                    # Count the number of values in each group\n",
    "                    pl.count(\"random\").alias(\"size\"),\n",
    "                    # Sample one element in each group\n",
    "                    pl.col(\"names\").apply(lambda group_df: group_df.sample(1)),\n",
    "                ]\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "    # Handling Missing Data\n",
    "    col3.subheader(\"Handling Missing Data\")\n",
    "\n",
    "    col3.code('''\n",
    "            # Drop rows with any column having a null value\n",
    "            df.drop_nulls()\n",
    "            ''')\n",
    "\n",
    "    col3.code('''\n",
    "            # Replace null values with given value\n",
    "            df.fill_null(42)\n",
    "            ''')\n",
    "\n",
    "    col3.code('''\n",
    "            # Replace null values using forward strategy\n",
    "            df.fill_null(strategy=\"forward\")\n",
    "            # Other fill strategies are \"backward\", \"min\", \"max\", \"mean\", \"zero\", and \"one\"\n",
    "            ''')\n",
    "\n",
    "    col3.code('''\n",
    "            # Replace floating point NaN values with given value\n",
    "            df.fill_nan(42)\n",
    "            ''')\n",
    "\n",
    "    # Combine Data Sets\n",
    "    col3.subheader(\"Combine Data Sets\")\n",
    "\n",
    "    col3.code('''\n",
    "            df4 = pl.DataFrame(\n",
    "                {\n",
    "                    \"nrs\": [1, 2, 5, 6],\n",
    "                    \"animals\": [\"cheetah\", \"lion\", \"leopard\", \"tiger\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Inner join\n",
    "            df.join(df4, on=\"nrs\", how=\"inner\")\n",
    "\n",
    "            # Left join\n",
    "            df.join(df4, on=\"nrs\", how=\"left\")\n",
    "\n",
    "            # Outer join\n",
    "            df.join(df4, on=\"nrs\", how=\"outer\")\n",
    "\n",
    "            # Anti join\n",
    "            df.join(df4, on=\"nrs\", how=\"anti\")\n",
    "            ''')\n",
    "\n",
    "    # Make New Columns\n",
    "    col3.subheader(\"Make New Columns\")\n",
    "\n",
    "    col3.code('''\n",
    "            # Add a new column to the DataFrame\n",
    "            df.with_column((pl.col(\"random\") * pl.col(\"nrs\")).alias(\"product\"))\n",
    "            ''')\n",
    "\n",
    "    col3.code('''\n",
    "            # Add several new columns to the DataFrame\n",
    "            df.with_columns(\n",
    "                [\n",
    "                    (pl.col(\"random\") * pl.col(\"nrs\")).alias(\"product\"),\n",
    "                    pl.col(\"names\").str.lengths().alias(\"names_lengths\"),\n",
    "                ]\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "    col3.code('''\n",
    "            # Add a column at index 0 that counts the rows\n",
    "            df.with_row_count()\n",
    "            ''')\n",
    "\n",
    "    # Rolling Functions\n",
    "    col3.subheader(\"Rolling Functions\")\n",
    "\n",
    "    col3.code('''\n",
    "            # Rolling Functions\n",
    "            df.select(\n",
    "                [\n",
    "                    pl.col(\"random\"),\n",
    "                    # Rolling maximum value\n",
    "                    pl.col(\"random\").rolling_max(window_size=2).alias(\"rolling_max\"),\n",
    "                    # Rolling mean value\n",
    "                    pl.col(\"random\").rolling_mean(window_size=2).alias(\"rolling_mean\"),\n",
    "                    # Rolling median value\n",
    "                    pl.col(\"random\")\n",
    "                    .rolling_median(window_size=2, min_periods=2)\n",
    "                    .alias(\"rolling_median\"),\n",
    "                    # ... (other rolling functions)\n",
    "                ]\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "    # Window Functions\n",
    "    col3.subheader(\"Window Functions\")\n",
    "    col3.code('''\n",
    "            # Window Functions\n",
    "            df.select(\n",
    "                [\n",
    "                    \"names\",\n",
    "                    \"groups\",\n",
    "                    pl.col(\"random\").sum().over(\"names\").alias(\"sum_by_names\"),\n",
    "                    pl.col(\"random\").sum().over(\"groups\").alias(\"sum_by_groups\"),\n",
    "                ]\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "\n",
    "# Run the main function if the script is executed directly\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py & npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
